{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyen-nhat-mai/methane-leak-detection/blob/main/Web_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-7rHnD4hm6M"
      },
      "source": [
        "# Build web app for classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "lSfR_PaYYrLk"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPD5lMyRa8Ph"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://towardsdatascience.com/create-an-image-classification-web-app-using-pytorch-and-streamlit-f043ddf00c24#2b4c\n",
        "https://www.youtube.com/watch?v=NEhrkeF2o_M"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the web app\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "#---------------------- TO UPDATE WITH FINAL MODEL-----------------------#\n",
        "def predict(image_path):\n",
        "    # Load model\n",
        "    best_model = models.resnet101(pretrained=True)\n",
        "    # Define transformation\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "      mean=[0.485, 0.456, 0.406],\n",
        "      std=[0.229, 0.224, 0.225]\n",
        "      )])\n",
        "    # Load data\n",
        "    img = Image.open(image_path)\n",
        "    batch_t = torch.unsqueeze(transform(img), 0)\n",
        "    # Do inference\n",
        "    best_model.eval()\n",
        "    out = best_model(batch_t)\n",
        "    # Load all of the classes => Yes/ No for methane case\n",
        "    with open('imagenet_classes.txt') as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    # Calculate the probability\n",
        "    prob = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    _, indices = torch.sort(out, descending=True)\n",
        "    # Return the classes and corresponding probability\n",
        "    return [(classes[idx], prob[idx].item()) for idx in indices[0][:1]]\n",
        "\n",
        "# ------------------------------WEB APP----------------------------------#\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "st.title(\"Detect Methane Leaks\")\n",
        "st.write(\"\")\n",
        "\n",
        "\n",
        "\n",
        "st.subheader(\"Prediction on uploaded images\")\n",
        "# Define a function to create a download link for a given DataFrame\n",
        "def download_link(df, filename, text):\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode('utf-8')).decode()  # base64 encoding\n",
        "    href = f\"data:text/csv;base64,{b64}\"\n",
        "    return f'<a href=\"{href}\" download=\"{filename}\">{text}</a>'\n",
        "\n",
        "file_up = st.file_uploader(\"Upload your images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "if file_up is not None:\n",
        "    # Print images and their predictions\n",
        "    all_predictions = pd.DataFrame() # create an empty DataFrame to store all predictions\n",
        "    for img_file in file_up:\n",
        "        image = Image.open(img_file)\n",
        "        st.image(image, caption=img_file.name, use_column_width=True)\n",
        "        st.write(\"\")\n",
        "        with st.spinner('Predicting...'):\n",
        "            predictions_df = predict(img_file)\n",
        "            # Append the current predictions to the DataFrame along with the file name\n",
        "            predictions_df = [(img_file.name,)+predictions_df[0]]\n",
        "            all_predictions = all_predictions.append(predictions_df, ignore_index=True) \n",
        "            # Print out the prediction labels with probability\n",
        "            for i in range(len(predictions_df)):\n",
        "                st.write(\"Prediction:\", all_predictions.iloc[i][1], \"-   Probability (%): \", all_predictions.iloc[i][2])\n",
        "    \n",
        "    \n",
        "    # Display summary and export the predictions to an CSV file\n",
        "    if not all_predictions.empty:\n",
        "        st.write(\"\")\n",
        "        all_predictions.columns = ['File name', 'Label', 'Probability (%)']\n",
        "        st.subheader(\"Prediction Detail\")\n",
        "        st.write(all_predictions)\n",
        "        all_predictions.to_csv(\"predictions.csv\", index=False)\n",
        "        st.markdown(download_link(all_predictions, \"predictions.csv\", \"Download CSV\"), unsafe_allow_html=True)"
      ],
      "metadata": {
        "id": "wdVDgJt4dEZ8",
        "outputId": "097db4de-b7c6-4ddb-aa28-752d9200ff27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run app.py and made available on a local URL\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD5UEGqkd0HL",
        "outputId": "f0fa95d0-0313-4c49-f241-2ed84f7e6264"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[############......] / install:get-caller-file: info lifecycle get-caller-file@\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.495s\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.139.171.39:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://lovely-owls-worry.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/content/app.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_predictions = all_predictions.append(predictions_df, ignore_index=True)\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}