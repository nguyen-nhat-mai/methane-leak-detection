{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyen-nhat-mai/methane-leak-detection/blob/main/Web_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-7rHnD4hm6M"
      },
      "source": [
        "# Build web app for classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lSfR_PaYYrLk",
        "outputId": "86a4aea4-d28f-45d4-8373-9ec7bb05e341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit_folium"
      ],
      "metadata": {
        "id": "VJ29Z1jkhO83",
        "outputId": "87b9e5d0-5eff-4a41-a119-28f13fb36d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit_folium\n",
            "  Downloading streamlit_folium-0.11.1-py3-none-any.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.4/423.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: streamlit>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (1.22.0)\n",
            "Requirement already satisfied: folium>=0.13 in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (0.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (3.1.2)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium>=0.13->streamlit_folium) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium>=0.13->streamlit_folium) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->streamlit_folium) (2.1.2)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (4.2.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (1.6.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (5.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (6.6.0)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (1.5.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (8.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (9.0.0)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (2.8.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (13.3.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (8.2.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (4.5.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (4.3)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (3.1.31)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (0.8.1b0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (6.3.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19->streamlit>=1.13.0->streamlit_folium) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit>=1.13.0->streamlit_folium) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit>=1.13.0->streamlit_folium) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit>=1.13.0->streamlit_folium) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit>=1.13.0->streamlit_folium) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit>=1.13.0->streamlit_folium) (2.14.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit>=1.13.0->streamlit_folium) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit>=1.13.0->streamlit_folium) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=1.13.0->streamlit_folium) (5.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit>=1.13.0->streamlit_folium) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit>=1.13.0->streamlit_folium) (2023.3)\n",
            "Installing collected packages: streamlit_folium\n",
            "Successfully installed streamlit_folium-0.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPD5lMyRa8Ph"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://towardsdatascience.com/create-an-image-classification-web-app-using-pytorch-and-streamlit-f043ddf00c24#2b4c\n",
        "https://www.youtube.com/watch?v=NEhrkeF2o_M"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the web app\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import altair as alt\n",
        "import folium\n",
        "from streamlit_folium import st_folium, folium_static\n",
        "\n",
        "#---------------------- TO UPDATE WITH FINAL MODEL-----------------------#\n",
        "\n",
        "def predict(image_path):\n",
        "    # Load model\n",
        "    best_model = models.resnet101(pretrained=True)\n",
        "    # Define transformation\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "      mean=[0.485, 0.456, 0.406],\n",
        "      std=[0.229, 0.224, 0.225]\n",
        "      )])\n",
        "    # Load data\n",
        "    img = Image.open(image_path)\n",
        "    batch_t = torch.unsqueeze(transform(img), 0)\n",
        "    # Do inference\n",
        "    best_model.eval()\n",
        "    out = best_model(batch_t)\n",
        "    # Load all of the classes => Yes/ No for methane case\n",
        "    with open('imagenet_classes.txt') as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    # Calculate the probability\n",
        "    prob = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    _, indices = torch.sort(out, descending=True)\n",
        "    # Return the classes and corresponding probability\n",
        "    return [(classes[idx], prob[idx].item()) for idx in indices[0][:1]]\n",
        "\n",
        "# ------------------------------WEB APP----------------------------------#\n",
        "\n",
        "# Define a function to create a download link for a given DataFrame\n",
        "def download_link(df, filename, text):\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode('utf-8')).decode()  # base64 encoding\n",
        "    href = f\"data:text/csv;base64,{b64}\"\n",
        "    return f'<a href=\"{href}\" download=\"{filename}\">{text}</a>'\n",
        "\n",
        "# Get dictionary of geolocation for id_coord\n",
        "geo_map = pd.read_csv(\"metadata.csv\")\n",
        "geo_dict = {row['id_coord']: (row['lat'], row['lon']) for _, row in geo_map.iterrows()}\n",
        "\n",
        "# Start the display on web app\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "st.title(\"CleanR - Detect Methane Leaks\")\n",
        "st.write(\"\")\n",
        "st.sidebar.header(\"Menu\")\n",
        "tabs = [\"Prediction on uploaded images\", \"Leak detection map\", \"Leak track over time by id_coord\", \"Prediction detail\"]\n",
        "selected_tab = st.sidebar.radio(\"\", tabs)\n",
        "\n",
        "\n",
        "if selected_tab == \"Prediction on uploaded images\":\n",
        "    file_up = st.file_uploader(\"Upload your images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "    if file_up is not None:\n",
        "        st.subheader(\"Prediction on uploaded images\")\n",
        "        all_predictions = pd.DataFrame() # create an empty DataFrame to store all predictions\n",
        "        for img_file in file_up:\n",
        "            image = Image.open(img_file)\n",
        "            st.image(image, caption=img_file.name, use_column_width=True)\n",
        "            st.write(\"\")\n",
        "            with st.spinner('Predicting...'):\n",
        "                predictions_df = predict(img_file)\n",
        "                # Append the current predictions to the DataFrame along with the id_coord, date and geolocation\n",
        "                id_coord = img_file.name.split(\".\")[0][-7:]\n",
        "                date = img_file.name.split(\"_\")[0]\n",
        "                latitude = geo_dict[id_coord][0]\n",
        "                longitude = geo_dict[id_coord][1]\n",
        "                predictions_df = [(id_coord,date,latitude,longitude,)+predictions_df[0]]\n",
        "                all_predictions = all_predictions.append(predictions_df, ignore_index=True)\n",
        "                # Print out the prediction labels with probability\n",
        "                st.write(\"Prediction:\", predictions_df[0][4], \"-   Probability (%): \", round(predictions_df[0][5],0))\n",
        "        if not all_predictions.empty:\n",
        "            all_predictions.columns = ['Id_coord', \"Date\",\"Latitude\",\"Longitude\",'Label', 'Probability (%)']\n",
        "            all_predictions.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "if selected_tab == \"Leak detection map\":\n",
        "    st.subheader(\"Leak detection map\")\n",
        "    all_predictions = pd.read_csv(\"predictions.csv\")\n",
        "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'], format='%Y%m%d')\n",
        "    # Create base map that will be centered around the mean latitude and longitude \n",
        "    m = folium.Map(location=[all_predictions.Latitude.mean(), all_predictions.Longitude.mean()], \n",
        "                 zoom_start=3, control_scale=True)\n",
        "    # Loop through each row in the dataframe\n",
        "    for i,row in all_predictions.iterrows():\n",
        "        # Setup the content of the popup\n",
        "        iframe = folium.IFrame('id:' + str(row[\"Id_coord\"]))\n",
        "        # Initialise the popup using the iframe\n",
        "        popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
        "        # Add each row to the map\n",
        "        folium.Marker(location=[row['Latitude'],row['Longitude']],\n",
        "                  popup = popup, c=row['Id_coord'],\n",
        "                  icon=folium.Icon(color='red',icon='info-sign')).add_to(m)\n",
        "    st_data = st_folium(m, width=700)\n",
        "\n",
        "if selected_tab == \"Leak track over time by id_coord\":\n",
        "    st.subheader(\"Leak track over time by id_coord\")\n",
        "    all_predictions = pd.read_csv(\"predictions.csv\")\n",
        "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'], format='%Y%m%d')\n",
        "    id_coord_list = list(all_predictions['Id_coord'].unique())\n",
        "    selected_id_coord = st.sidebar.selectbox(\"Select an id_coord:\", id_coord_list)\n",
        "    filtered_predictions = all_predictions.loc[all_predictions['Id_coord'] == selected_id_coord]\n",
        "    chart = alt.Chart(filtered_predictions).mark_line(color=\"#ff2b2b\").encode(x='Date',y='Probability (%)')\n",
        "    st.altair_chart(chart, use_container_width=True)\n",
        "\n",
        "if selected_tab == \"Prediction detail\":\n",
        "    st.subheader(\"Prediction Detail\")\n",
        "    all_predictions = pd.read_csv(\"predictions.csv\")\n",
        "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'], format='%Y%m%d')\n",
        "    st.markdown(download_link(all_predictions, \"prediction.csv\", \"Download CSV\"), unsafe_allow_html=True)\n",
        "    st.write(\"\")\n",
        "    st.write(all_predictions)"
      ],
      "metadata": {
        "id": "jVi5w0dobYkP",
        "outputId": "fd707ac5-5fa1-4af0-db77-c8e23a72a146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run app.py and made available on a local URL\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD5UEGqkd0HL",
        "outputId": "c286691f-c7c2-4973-e047-857150304ce9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.251s\n",
            "your url is: https://long-forks-do.loca.lt\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.229.190:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2023-05-14 11:51:30.322 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-14 11:51:36.073 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/content/app.py:81: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_predictions = all_predictions.append(predictions_df, ignore_index=True)\n",
            "2023-05-14 11:51:52.153 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-14 11:51:53.320 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-14 11:51:59.788 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-14 11:52:00.865 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-14 11:52:02.252 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-14 11:52:03.570 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}