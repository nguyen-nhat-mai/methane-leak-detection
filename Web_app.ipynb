{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyen-nhat-mai/methane-leak-detection/blob/main/Web_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-7rHnD4hm6M"
      },
      "source": [
        "# Build web app for classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "lSfR_PaYYrLk"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit_folium"
      ],
      "metadata": {
        "id": "VJ29Z1jkhO83",
        "outputId": "8a57fbb7-4aed-4239-f9e4-d15146e343fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: streamlit_folium in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: streamlit>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (1.22.0)\n",
            "Requirement already satisfied: folium>=0.13 in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (0.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (3.1.2)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.10/dist-packages (from streamlit_folium) (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from folium>=0.13->streamlit_folium) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from folium>=0.13->streamlit_folium) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->streamlit_folium) (2.1.2)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (4.2.2)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (1.6.2)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (5.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (8.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (6.6.0)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (1.5.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (8.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (9.0.0)\n",
            "Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (2.8.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (13.3.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (8.2.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (4.5.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (4.3)\n",
            "Requirement already satisfied: validators>=0.2 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (0.20.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (3.1.31)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (0.8.1b0)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (6.3.1)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.10/dist-packages (from streamlit>=1.13.0->streamlit_folium) (3.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (0.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19->streamlit>=1.13.0->streamlit_folium) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit>=1.13.0->streamlit_folium) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit>=1.13.0->streamlit_folium) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit>=1.13.0->streamlit_folium) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->folium>=0.13->streamlit_folium) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit>=1.13.0->streamlit_folium) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit>=1.13.0->streamlit_folium) (2.14.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit>=1.13.0->streamlit_folium) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit>=1.13.0->streamlit_folium) (4.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit>=1.13.0->streamlit_folium) (5.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit>=1.13.0->streamlit_folium) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit>=1.13.0->streamlit_folium) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit>=1.13.0->streamlit_folium) (2023.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the airquality first to avoid web app lag\n",
        "metadata=pd.read_csv(\"metadata.csv\")\n",
        "import requests\n",
        "import json\n",
        "# Define the base API URL\n",
        "api_url = 'https://air-quality-api.open-meteo.com/v1/air-quality'\n",
        "\n",
        "# Create empty lists to store the API responses\n",
        "api_responses = []\n",
        "\n",
        "# Iterate over the rows of the DataFrame\n",
        "for index, row in metadata.iterrows():\n",
        "    # Get the latitude and longitude values from the current row\n",
        "    latitude = row['lat']\n",
        "    longitude = row['lon']\n",
        "    \n",
        "    # Create the API URL with the latitude and longitude parameters\n",
        "    url = f'{api_url}?latitude={latitude}&longitude={longitude}&hourly=european_aqi&start_date=2022-08-01&end_date=2023-01-31'\n",
        "    \n",
        "    # Send the API request\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    # Check if the request was successful\n",
        "    if response.status_code == requests.codes.ok:\n",
        "        # Append the API response to the list\n",
        "        api_responses.append(np.mean([value for value in json.loads(response.text)[\"hourly\"][\"european_aqi\"] if value is not None]))\n",
        "    else:\n",
        "        # Handle the error if the request was not successful\n",
        "        print(f\"Error for latitude {latitude}, longitude {longitude}: {response.status_code}, {response.text}\")\n",
        "metadata['api_response'] = api_responses\n",
        "metadata.head()"
      ],
      "metadata": {
        "id": "SEOOPcjDmcgY",
        "outputId": "caa786fa-1347-4674-a1bd-c6c90d308b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       date id_coord plume    set        lat         lon  coord_x  coord_y  \\\n",
              "0  20230223  id_6675   yes  train  31.528750   74.330625       24       47   \n",
              "1  20230103  id_2542   yes  train  35.538000  112.524000       42       37   \n",
              "2  20230301  id_6546   yes  train  21.060000   84.936667       58       15   \n",
              "3  20230225  id_6084   yes  train  26.756667   80.973333       28       62   \n",
              "4  20230105  id_2012   yes  train  34.800000   40.770000       59       44   \n",
              "\n",
              "                                                path  api_response  \n",
              "0  images/plume/20230223_methane_mixing_ratio_id_...    117.434028  \n",
              "1  images/plume/20230103_methane_mixing_ratio_id_...     70.871991  \n",
              "2  images/plume/20230301_methane_mixing_ratio_id_...     68.038426  \n",
              "3  images/plume/20230225_methane_mixing_ratio_id_...     99.746296  \n",
              "4  images/plume/20230105_methane_mixing_ratio_id_...     35.661111  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cc41efa-6e95-44e4-9b99-fb2a283fb447\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>id_coord</th>\n",
              "      <th>plume</th>\n",
              "      <th>set</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>coord_x</th>\n",
              "      <th>coord_y</th>\n",
              "      <th>path</th>\n",
              "      <th>api_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20230223</td>\n",
              "      <td>id_6675</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>31.528750</td>\n",
              "      <td>74.330625</td>\n",
              "      <td>24</td>\n",
              "      <td>47</td>\n",
              "      <td>images/plume/20230223_methane_mixing_ratio_id_...</td>\n",
              "      <td>117.434028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20230103</td>\n",
              "      <td>id_2542</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>35.538000</td>\n",
              "      <td>112.524000</td>\n",
              "      <td>42</td>\n",
              "      <td>37</td>\n",
              "      <td>images/plume/20230103_methane_mixing_ratio_id_...</td>\n",
              "      <td>70.871991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20230301</td>\n",
              "      <td>id_6546</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>21.060000</td>\n",
              "      <td>84.936667</td>\n",
              "      <td>58</td>\n",
              "      <td>15</td>\n",
              "      <td>images/plume/20230301_methane_mixing_ratio_id_...</td>\n",
              "      <td>68.038426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20230225</td>\n",
              "      <td>id_6084</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>26.756667</td>\n",
              "      <td>80.973333</td>\n",
              "      <td>28</td>\n",
              "      <td>62</td>\n",
              "      <td>images/plume/20230225_methane_mixing_ratio_id_...</td>\n",
              "      <td>99.746296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20230105</td>\n",
              "      <td>id_2012</td>\n",
              "      <td>yes</td>\n",
              "      <td>train</td>\n",
              "      <td>34.800000</td>\n",
              "      <td>40.770000</td>\n",
              "      <td>59</td>\n",
              "      <td>44</td>\n",
              "      <td>images/plume/20230105_methane_mixing_ratio_id_...</td>\n",
              "      <td>35.661111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cc41efa-6e95-44e4-9b99-fb2a283fb447')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cc41efa-6e95-44e4-9b99-fb2a283fb447 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cc41efa-6e95-44e4-9b99-fb2a283fb447');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata.to_csv('metadata_aq.csv', index=False)"
      ],
      "metadata": {
        "id": "iaDDKgSfotQS"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPD5lMyRa8Ph"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://towardsdatascience.com/create-an-image-classification-web-app-using-pytorch-and-streamlit-f043ddf00c24#2b4c\n",
        "https://www.youtube.com/watch?v=NEhrkeF2o_M"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the web app\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from PIL import Image\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import base64\n",
        "from io import BytesIO\n",
        "import altair as alt\n",
        "import folium\n",
        "from streamlit_folium import st_folium, folium_static\n",
        "import requests\n",
        "import json\n",
        "\n",
        "#---------------------- MODEL PREDICTION-----------------------#\n",
        "   \n",
        "def preprocess_image(img):\n",
        "    img = img.resize((64, 64), Image.ANTIALIAS)  # Resize the image\n",
        "    data = np.array(img)\n",
        "    data = np.expand_dims(data, axis=-1)\n",
        "    data = data.astype('float32') / 255.0\n",
        "    return np.array([data])\n",
        "\n",
        "def preprocess_location(image_name,df_normalized):\n",
        "    matching_row = df_normalized[df_normalized['path'].str.contains(image_name)]\n",
        "    lat = matching_row['lat'].values[0]\n",
        "    api_response = matching_row['api_response'].values[0]\n",
        "    lon = matching_row['lon'].values[0]\n",
        "    coord_x = matching_row['coord_x'].values[0]\n",
        "    coord_y = matching_row['coord_y'].values[0]\n",
        "    return np.array([[lat, api_response, lon, coord_x, coord_y]])\n",
        "\n",
        "def predict(image, image_name, df_normalized):\n",
        "    # Load model\n",
        "    model = tf.keras.models.load_model(\"model_v2.h5\")\n",
        "    # Load data\n",
        "    loc_data = preprocess_location(image_name,df_normalized)\n",
        "    img_data = preprocess_image(image)\n",
        "    # Do inference\n",
        "    y_pred = model.predict({\"location\": loc_data, \"img\": img_data})\n",
        "    y_prob = y_pred.flatten()*100\n",
        "\n",
        "    max_idx = np.argmax(y_prob)\n",
        "    max_prob = y_prob[max_idx]\n",
        "\n",
        "    y_class = (y_pred >= 0.5).astype(int).flatten()\n",
        "    max_class = y_class[max_idx]\n",
        "\n",
        "    # Return the class and corresponding probability\n",
        "    return [(max_class, max_prob)]\n",
        "\n",
        "# ------------------------------WEB APP----------------------------------#\n",
        "\n",
        "# Define a function to create a download link for a given DataFrame\n",
        "def download_link(df, filename, text):\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode('utf-8')).decode()  # base64 encoding\n",
        "    href = f\"data:text/csv;base64,{b64}\"\n",
        "    return f'<a href=\"{href}\" download=\"{filename}\">{text}</a>'\n",
        "\n",
        "# Get dictionary of geolocation for id_coord\n",
        "geo_map = pd.read_csv(\"metadata_aq.csv\")\n",
        "geo_dict = {row['id_coord']: (row['lat'], row['lon']) for _, row in geo_map.iterrows()}\n",
        "\n",
        "# Get the normalized location\n",
        "scaler = MinMaxScaler()\n",
        "scaled_values = scaler.fit_transform(geo_map[['lat', 'lon']])\n",
        "df_normalized = geo_map.copy()\n",
        "df_normalized[['lat', 'lon']] = scaled_values\n",
        "\n",
        "# Start the display on web app\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "st.title(\"CleanR - Detect Methane Leaks\")\n",
        "st.write(\"\")\n",
        "st.sidebar.header(\"Menu\")\n",
        "tabs = [\"Prediction on uploaded images\", \"Leak detection map\", \"Leak track over time by id_coord\", \"Prediction detail\"]\n",
        "selected_tab = st.sidebar.radio(\"\", tabs)\n",
        "\n",
        "\n",
        "if selected_tab == \"Prediction on uploaded images\":\n",
        "    file_up = st.file_uploader(\"Upload your images\", type=[\"jpg\", \"jpeg\", \"png\",\"tif\", \"tiff\"], accept_multiple_files=True)\n",
        "    if file_up is not None:\n",
        "        st.subheader(\"Prediction on uploaded images\")\n",
        "        all_predictions = pd.DataFrame() # create an empty DataFrame to store all predictions\n",
        "        for img_file in file_up:\n",
        "            image = Image.open(img_file)\n",
        "            image_8bit = image.convert(\"L\")\n",
        "            st.image(image_8bit, caption=img_file.name, use_column_width=True)\n",
        "            st.write(\"\")\n",
        "            with st.spinner('Predicting...'):\n",
        "                # Get prediction result\n",
        "                predictions_df = predict(image_8bit,img_file.name.split(\".\")[0], df_normalized)\n",
        "                # Append the current predictions to the DataFrame along with the id_coord, date and geolocation\n",
        "                id_coord = img_file.name.split(\".\")[0][-7:]\n",
        "                date = img_file.name.split(\"_\")[0]\n",
        "                latitude = geo_dict[id_coord][0]\n",
        "                longitude = geo_dict[id_coord][1]\n",
        "                predictions_df = [(id_coord,date,latitude,longitude,)+predictions_df[0]]\n",
        "                all_predictions = all_predictions.append(predictions_df, ignore_index=True)\n",
        "                # Print out the prediction labels with probability\n",
        "                st.write(\"Prediction:\", predictions_df[0][4], \"-   Probability (%): \", round(predictions_df[0][5],1))\n",
        "        if not all_predictions.empty:\n",
        "            all_predictions.columns = ['Id_coord', \"Date\",\"Latitude\",\"Longitude\",'Label', 'Probability (%)']\n",
        "            all_predictions.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "if selected_tab == \"Leak detection map\":\n",
        "    st.subheader(\"Leak detection map\")\n",
        "    all_predictions = pd.read_csv(\"predictions.csv\")\n",
        "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'], format='%Y%m%d')\n",
        "    # Create base map that will be centered around the mean latitude and longitude \n",
        "    m = folium.Map(location=[all_predictions.Latitude.mean(), all_predictions.Longitude.mean()], \n",
        "                 zoom_start=3, control_scale=True)\n",
        "    # Loop through each row in the dataframe\n",
        "    for i,row in all_predictions.iterrows():\n",
        "        # Setup the content of the popup\n",
        "        iframe = folium.IFrame('id:' + str(row[\"Id_coord\"]))\n",
        "        # Initialise the popup using the iframe\n",
        "        popup = folium.Popup(iframe, min_width=300, max_width=300)\n",
        "        # Add each row to the map\n",
        "        folium.Marker(location=[row['Latitude'],row['Longitude']],\n",
        "                  popup = popup, c=row['Id_coord'],\n",
        "                  icon=folium.Icon(color='red',icon='info-sign')).add_to(m)\n",
        "    st_data = st_folium(m, width=700)\n",
        "\n",
        "if selected_tab == \"Leak track over time by id_coord\":\n",
        "    st.subheader(\"Leak track over time by id_coord\")\n",
        "    all_predictions = pd.read_csv(\"predictions.csv\")\n",
        "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'], format='%Y%m%d')\n",
        "    id_coord_list = list(all_predictions['Id_coord'].unique())\n",
        "    selected_id_coord = st.sidebar.selectbox(\"Select an id_coord:\", id_coord_list)\n",
        "    filtered_predictions = all_predictions.loc[all_predictions['Id_coord'] == selected_id_coord]\n",
        "    chart = alt.Chart(filtered_predictions).mark_line(color=\"#ff2b2b\").encode(x='Date',y='Probability (%)')\n",
        "    st.altair_chart(chart, use_container_width=True)\n",
        "\n",
        "if selected_tab == \"Prediction detail\":\n",
        "    st.subheader(\"Prediction Detail\")\n",
        "    all_predictions = pd.read_csv(\"predictions.csv\")\n",
        "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'], format='%Y%m%d')\n",
        "    st.markdown(download_link(all_predictions, \"prediction.csv\", \"Download CSV\"), unsafe_allow_html=True)\n",
        "    st.write(\"\")\n",
        "    st.write(all_predictions)"
      ],
      "metadata": {
        "id": "jVi5w0dobYkP",
        "outputId": "a3ed109c-31e5-43b4-9802-88ce3b5f1413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run app.py and made available on a local URL\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD5UEGqkd0HL",
        "outputId": "a936252c-fbb9-4791-dfee-a9dadc7191eb"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.149s\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.49.100:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://thick-teams-take.loca.lt\n",
            "2023-05-15 13:42:27.843266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-15 13:42:30.564 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2023-05-15 13:42:37.938 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "/content/app.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_predictions = all_predictions.append(predictions_df, ignore_index=True)\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "2023-05-15 13:42:49.297 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f075a41edd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "/content/app.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_predictions = all_predictions.append(predictions_df, ignore_index=True)\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06e2163f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}