{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyen-nhat-mai/methane-leak-detection/blob/main/Web_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-7rHnD4hm6M"
      },
      "source": [
        "# Build web app for classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lSfR_PaYYrLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb7e2d9-901d-4786-c196-6c57d75f5635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ver 1: Upload and infer image by image\n",
        "\n"
      ],
      "metadata": {
        "id": "wvi_isiIcvUq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPD5lMyRa8Ph"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://towardsdatascience.com/create-an-image-classification-web-app-using-pytorch-and-streamlit-f043ddf00c24#2b4c\n",
        "https://www.youtube.com/watch?v=NEhrkeF2o_M"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMtGOJ0FYuDT",
        "outputId": "74bac1c1-4494-4e07-b4a9-f7b6d606f859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "# Write the web app\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "\n",
        "#---------------------- TO UPDATE WITH FINAL MODEL-----------------------#\n",
        "def predict(image_path):\n",
        "    # Load model\n",
        "    best_model = models.resnet101(pretrained=True)\n",
        "    # Define transformation\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "      mean=[0.485, 0.456, 0.406],\n",
        "      std=[0.229, 0.224, 0.225]\n",
        "      )])\n",
        "    # Load data\n",
        "    img = Image.open(image_path)\n",
        "    batch_t = torch.unsqueeze(transform(img), 0)\n",
        "    # Do inference\n",
        "    best_model.eval()\n",
        "    out = best_model(batch_t)\n",
        "    # Load all of the classes => Yes/ No for methane case\n",
        "    with open('imagenet_classes.txt') as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    # Calculate the probability\n",
        "    prob = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    _, indices = torch.sort(out, descending=True)\n",
        "    # Return the classes and corresponding probability\n",
        "    return [(classes[idx], prob[idx].item()) for idx in indices[0][:2]]\n",
        "\n",
        "# ------------------------------WEB APP----------------------------------#\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "\n",
        "st.title(\"Localize Methane Leaks\")\n",
        "st.write(\"\")\n",
        "\n",
        "file_up = st.file_uploader(\"Upload an image\", type=\"jpg\")\n",
        "\n",
        "if file_up is not None:\n",
        "    image = Image.open(file_up)\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Just a second...\")\n",
        "    labels = predict(file_up)\n",
        "\n",
        "    # print out the prediction labels with scores\n",
        "    for i in labels:\n",
        "        st.write(\"Prediction:\", i[0], \",   Probability (%): \", i[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1-u_S0Vbltc",
        "outputId": "c2a9637b-0c1e-4db7-b15c-d2d137fdeb28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[#######...........] / extract:localtunnel: verb lock using /root/.npm/_locks/s\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.143.211:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.458s\n",
            "your url is: https://chatty-tigers-relate.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Run app.py and made available on a local URL\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ver 2: Upload batch of images and export results"
      ],
      "metadata": {
        "id": "6cuHW-O5c7VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the web app\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "import torch\n",
        "import time\n",
        "import pandas as pd\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "#---------------------- TO UPDATE WITH FINAL MODEL-----------------------#\n",
        "def predict(image_path):\n",
        "    # Load model\n",
        "    best_model = models.resnet101(pretrained=True)\n",
        "    # Define transformation\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "      mean=[0.485, 0.456, 0.406],\n",
        "      std=[0.229, 0.224, 0.225]\n",
        "      )])\n",
        "    # Load data\n",
        "    img = Image.open(image_path)\n",
        "    batch_t = torch.unsqueeze(transform(img), 0)\n",
        "    # Do inference\n",
        "    best_model.eval()\n",
        "    out = best_model(batch_t)\n",
        "    # Load all of the classes => Yes/ No for methane case\n",
        "    with open('imagenet_classes.txt') as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    # Calculate the probability\n",
        "    prob = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    _, indices = torch.sort(out, descending=True)\n",
        "    # Return the classes and corresponding probability\n",
        "    return [(classes[idx], prob[idx].item()) for idx in indices[0][:2]]\n",
        "\n",
        "# ------------------------------WEB APP----------------------------------#\n",
        "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
        "st.title(\"Detect Methane Leaks\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Define a function to create a download link for a given DataFrame\n",
        "def download_link(df, filename, text):\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode('utf-8')).decode()  # base64 encoding\n",
        "    href = f\"data:text/csv;base64,{b64}\"\n",
        "    return f'<a href=\"{href}\" download=\"{filename}\">{text}</a>'\n",
        "\n",
        "file_up = st.file_uploader(\"Upload your images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "if file_up is not None:\n",
        "    # Print images and their predictions\n",
        "    all_predictions = pd.DataFrame() # create an empty DataFrame to store all predictions\n",
        "    for img_file in file_up:\n",
        "        image = Image.open(img_file)\n",
        "        st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "        st.write(\"\")\n",
        "        with st.spinner('Predicting...'):\n",
        "            predictions_df = predict(img_file)\n",
        "            all_predictions = all_predictions.append(predictions_df, ignore_index=True) # append the current predictions to the DataFrame\n",
        "            # print out the prediction labels with probability\n",
        "            for i in range(len(predictions_df)):\n",
        "                st.write(\"Prediction:\", all_predictions.iloc[i][0], \"-   Probability (%): \", all_predictions.iloc[i][1])\n",
        "\n",
        "    # Export the predictions to an CSV file\n",
        "    st.write(\"\")\n",
        "    if not all_predictions.empty:\n",
        "        all_predictions.columns = ['Label', 'Probability (%)']\n",
        "        all_predictions.to_csv(\"predictions.csv\", index=False)\n",
        "        # Create a download button for the CSV file\n",
        "        download_button = st.button(label=\"Click here to download the predictions\")\n",
        "        if download_button:\n",
        "            st.markdown(download_link(all_predictions, \"predictions.csv\", \"Download CSV\"), unsafe_allow_html=True)"
      ],
      "metadata": {
        "id": "wdVDgJt4dEZ8",
        "outputId": "a8c17d69-531b-404b-d42f-8b4eb9b6dc6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run app.py and made available on a local URL\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD5UEGqkd0HL",
        "outputId": "b819a5a1-05e3-421d-aaaf-65ccfe063811"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.903s\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.139.171.39:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://nasty-vans-end.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/content/app.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_predictions = all_predictions.append(predictions_df, ignore_index=True) # append the current predictions to the DataFrame\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/content/app.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  all_predictions = all_predictions.append(predictions_df, ignore_index=True) # append the current predictions to the DataFrame\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}